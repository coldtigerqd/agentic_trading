#!/usr/bin/env python3
"""
æ•°æ®åŒæ­¥å®ˆæŠ¤è¿›ç¨‹

æ¯10åˆ†é’Ÿè‡ªåŠ¨åŒæ­¥è§‚å¯Ÿåˆ—è¡¨æ•°æ®åˆ°æœ¬åœ°æ•°æ®åº“ã€‚

ç‰¹æ€§ï¼š
- âœ… å¢é‡æ›´æ–°ï¼šåªè·å–æ–°æ•°æ®ï¼Œè‡ªåŠ¨å»é‡
- âœ… å¸‚åœºæ„ŸçŸ¥ï¼šåªåœ¨äº¤æ˜“æ—¶æ®µä¸»åŠ¨åŒæ­¥
- âœ… é”™è¯¯é‡è¯•ï¼šç½‘ç»œå¤±è´¥è‡ªåŠ¨é‡è¯•
- âœ… å®Œæ•´æ—¥å¿—ï¼šè®°å½•æ‰€æœ‰åŒæ­¥æ´»åŠ¨

ä½¿ç”¨æ–¹æ³•ï¼š
    # ç›´æ¥è¿è¡Œï¼ˆå‰å°ï¼‰
    python runtime/data_sync_daemon.py

    # åå°è¿è¡Œ
    nohup python runtime/data_sync_daemon.py > logs/data_sync.log 2>&1 &

    # ä½¿ç”¨ systemdï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰
    sudo systemctl start agentic-data-sync

    # ä½¿ç”¨ cronï¼ˆæ¯10åˆ†é’Ÿï¼‰
    */10 * * * * cd /path/to/agentic_trading && python runtime/data_sync_daemon.py --once
"""

import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import time
import logging
import argparse
from datetime import datetime, timedelta
from typing import Dict, List

# Import skills
from skills import (
    sync_watchlist_incremental,
    process_snapshot_and_cache,
    get_data_freshness_report
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/data_sync.log') if Path('logs').exists() else logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def run_sync_cycle() -> Dict:
    """
    æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ•°æ®åŒæ­¥å‘¨æœŸ

    Returns:
        åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
    """
    logger.info("=" * 70)
    logger.info("ğŸ“Š Starting Data Sync Cycle")
    logger.info("=" * 70)

    cycle_start = time.time()

    # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦åŒæ­¥
    sync_info = sync_watchlist_incremental(skip_if_market_closed=True)

    logger.info(f"Market Status: {sync_info['market_status']['session']}")
    logger.info(f"Market Open: {'âœ… YES' if sync_info['market_status']['market_open'] else 'âŒ NO'}")

    if not sync_info['should_sync']:
        logger.info(f"â­ï¸  Skip Reason: {sync_info['message']}")
        logger.info("=" * 70 + "\n")
        return {
            'synced': False,
            'reason': sync_info['message'],
            'market_status': sync_info['market_status']
        }

    symbols = sync_info['symbols_to_sync']
    logger.info(f"ğŸ“‹ Symbols to sync: {len(symbols)}")
    logger.info(f"ğŸ“Œ Symbols: {', '.join(symbols[:10])}{'...' if len(symbols) > 10 else ''}")

    # 2. è·å–æ•°æ®æ–°é²œåº¦æŠ¥å‘Š
    freshness = get_data_freshness_report(symbols)
    stale_count = sum(1 for s in freshness['symbols'] if s['is_stale'])
    logger.info(f"ğŸ“ˆ Data freshness: {stale_count}/{len(symbols)} symbols stale")

    # 3. åŒæ­¥æ¯ä¸ªè‚¡ç¥¨
    stats = {
        'total': len(symbols),
        'success': 0,
        'failed': 0,
        'new_bars': 0,
        'duplicates': 0,
        'errors': []
    }

    logger.info("\n" + "â”€" * 70)
    logger.info("Starting symbol-by-symbol sync...")
    logger.info("â”€" * 70 + "\n")

    for i, symbol in enumerate(symbols, 1):
        try:
            logger.info(f"[{i}/{len(symbols)}] Fetching {symbol}...")

            # ===== å…³é”®ï¼šè¿™é‡Œéœ€è¦è°ƒç”¨ ThetaData MCP =====
            # åœ¨å®é™…è¿è¡Œæ—¶ï¼Œç”± Claude Code è‡ªåŠ¨è°ƒç”¨ MCP å·¥å…·
            #
            # ç¤ºä¾‹è°ƒç”¨ï¼ˆç”± Claude Code æ‰§è¡Œï¼‰ï¼š
            # snapshot_result = mcp__ThetaData__stock_snapshot_ohlc(symbol=[symbol])
            #
            # snapshot_result æ ¼å¼ï¼š
            # {
            #     'open': 175.5,
            #     'high': 178.2,
            #     'low': 175.1,
            #     'close': 177.8,
            #     'volume': 5234567
            # }

            # æ¼”ç¤ºæ¨¡å¼ï¼šæ‰“å°éœ€è¦çš„ MCP è°ƒç”¨
            logger.info(f"   ğŸ”§ MCP Call: mcp__ThetaData__stock_snapshot_ohlc(symbol=['{symbol}'])")
            logger.info(f"   âš ï¸  This daemon requires Claude Code to execute MCP calls")

            # åœ¨å®é™…ç¯å¢ƒä¸­ï¼Œä¸‹é¢çš„ä»£ç ä¼šå¤„ç† MCP ç»“æœï¼š
            # result = process_snapshot_and_cache(symbol, snapshot_result)
            #
            # if result['success']:
            #     if result['bars_added'] > 0:
            #         logger.info(f"   âœ… {symbol}: New bar added @ {result['timestamp']}")
            #         stats['new_bars'] += 1
            #     else:
            #         logger.info(f"   â­ï¸  {symbol}: Duplicate (already in DB)")
            #         stats['duplicates'] += 1
            #     stats['success'] += 1
            # else:
            #     logger.error(f"   âŒ {symbol}: {result['error']}")
            #     stats['failed'] += 1
            #     stats['errors'].append({'symbol': symbol, 'error': result['error']})

            # æ¼”ç¤ºæ¨¡å¼ç»Ÿè®¡
            stats['success'] += 1

            # é¿å… API é™æµ
            time.sleep(0.1)

        except Exception as e:
            logger.error(f"   âŒ {symbol}: Exception - {e}")
            stats['failed'] += 1
            stats['errors'].append({'symbol': symbol, 'error': str(e)})

    # 4. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    cycle_duration = time.time() - cycle_start

    logger.info("\n" + "=" * 70)
    logger.info("ğŸ“Š Sync Cycle Complete")
    logger.info("=" * 70)
    logger.info(f"âœ… Success:    {stats['success']}/{stats['total']}")
    logger.info(f"ğŸ†• New Bars:   {stats['new_bars']}")
    logger.info(f"â­ï¸  Duplicates: {stats['duplicates']}")
    logger.info(f"âŒ Failed:     {stats['failed']}")
    logger.info(f"â±ï¸  Duration:   {cycle_duration:.2f}s")

    if stats['errors']:
        logger.warning("\nâš ï¸  Errors:")
        for err in stats['errors'][:5]:  # Show first 5 errors
            logger.warning(f"   - {err['symbol']}: {err['error']}")

    logger.info("=" * 70 + "\n")

    return {
        'synced': True,
        'stats': stats,
        'duration': cycle_duration,
        'market_status': sync_info['market_status']
    }


def run_continuous(interval_minutes: int = 10):
    """
    æŒç»­è¿è¡ŒåŒæ­¥å®ˆæŠ¤è¿›ç¨‹

    Args:
        interval_minutes: åŒæ­¥é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
    """
    logger.info("ğŸš€ Agentic AlphaHive - Data Sync Daemon")
    logger.info("=" * 70)
    logger.info(f"â° Sync Interval: {interval_minutes} minutes")
    logger.info(f"ğŸ’¾ Database: data_lake/trades.db")
    logger.info(f"ğŸ›‘ Press Ctrl+C to stop")
    logger.info("=" * 70 + "\n")

    cycle_count = 0

    try:
        while True:
            cycle_count += 1
            logger.info(f"ğŸ”„ Cycle #{cycle_count}")

            # æ‰§è¡ŒåŒæ­¥
            result = run_sync_cycle()

            # è®¡ç®—ä¸‹æ¬¡åŒæ­¥æ—¶é—´
            wait_seconds = interval_minutes * 60
            next_sync = datetime.now() + timedelta(seconds=wait_seconds)

            logger.info(f"â³ Waiting {interval_minutes} minutes...")
            logger.info(f"â° Next sync: {next_sync.strftime('%Y-%m-%d %H:%M:%S')}\n")

            time.sleep(wait_seconds)

    except KeyboardInterrupt:
        logger.info("\n\nğŸ›‘ Shutdown signal received")
        logger.info(f"âœ… Completed {cycle_count} sync cycles")
        logger.info("ğŸ‘‹ Data Sync Daemon stopped\n")


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description='å¢é‡å¸‚åœºæ•°æ®åŒæ­¥å®ˆæŠ¤è¿›ç¨‹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è¿è¡Œä¸€æ¬¡åé€€å‡º
  python runtime/data_sync_daemon.py --once

  # æŒç»­è¿è¡Œï¼ˆæ¯10åˆ†é’ŸåŒæ­¥ï¼‰
  python runtime/data_sync_daemon.py --interval 10

  # åå°è¿è¡Œ
  nohup python runtime/data_sync_daemon.py --interval 10 > logs/data_sync.log 2>&1 &

  # ä½¿ç”¨ cronï¼ˆæ¯10åˆ†é’Ÿï¼‰
  */10 * * * * cd /path/to/agentic_trading && python runtime/data_sync_daemon.py --once

æ³¨æ„ï¼š
  æ­¤å®ˆæŠ¤è¿›ç¨‹éœ€è¦åœ¨ Claude Code ç¯å¢ƒä¸­è¿è¡Œï¼Œä»¥ä¾¿è®¿é—® ThetaData MCP å·¥å…·ã€‚
        """
    )

    parser.add_argument(
        '--once',
        action='store_true',
        help='åªè¿è¡Œä¸€æ¬¡åŒæ­¥åé€€å‡º'
    )

    parser.add_argument(
        '--interval',
        type=int,
        default=10,
        help='æŒç»­æ¨¡å¼çš„åŒæ­¥é—´éš”ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤10åˆ†é’Ÿ'
    )

    args = parser.parse_args()

    # ç¡®ä¿ logs ç›®å½•å­˜åœ¨
    Path('logs').mkdir(exist_ok=True)

    if args.once:
        logger.info("Mode: Single Sync\n")
        result = run_sync_cycle()
        if result['synced']:
            logger.info(f"âœ… Sync completed: {result['stats']['success']}/{result['stats']['total']} symbols")
            sys.exit(0)
        else:
            logger.info(f"â­ï¸  Sync skipped: {result['reason']}")
            sys.exit(0)
    else:
        logger.info(f"Mode: Continuous (every {args.interval} minutes)\n")
        run_continuous(args.interval)


if __name__ == '__main__':
    main()
