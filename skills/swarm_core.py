"""
èœ‚ç¾¤æ™ºèƒ½æ ¸å¿ƒ - å¹¶å‘æ™ºèƒ½ä½“åè°ƒã€‚

è¿™æ˜¯é€’å½’æ™ºèƒ½å¼•æ“ï¼Œå¹¶å‘æ‰§è¡Œå¤šä¸ªç­–ç•¥å®ä¾‹å¹¶èšåˆå…¶ä¿¡å·ã€‚
"""

import asyncio
import json
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
from dataclasses import dataclass
from jinja2 import Template, Environment, FileSystemLoader, StrictUndefined

from data_lake.snapshot_manager import save_snapshot, update_snapshot_response
from skills.signal_enrichment import enrich_signal, validate_enriched_signal


# è·¯å¾„
SWARM_BASE = Path(__file__).parent.parent / "swarm_intelligence"
TEMPLATES_DIR = SWARM_BASE / "templates"
INSTANCES_DIR = SWARM_BASE / "active_instances"


@dataclass
class Signal:
    """èœ‚ç¾¤å®ä¾‹çš„äº¤æ˜“ä¿¡å·"""
    instance_id: str
    template_used: str
    target: str
    signal: str  # ä¾‹å¦‚ "SHORT_PUT_SPREAD", "LONG_CALL", "NO_TRADE"
    params: Dict[str, Any]
    confidence: float  # 0.0 åˆ° 1.0
    reasoning: str


def load_instances(sector_filter: Optional[str] = None) -> List[Dict]:
    """
    ä» JSON æ–‡ä»¶åŠ è½½æ´»è·ƒå®ä¾‹é…ç½®ã€‚

    å‚æ•°:
        sector_filter: æŒ‰è¡Œä¸šè¿‡æ»¤ï¼ˆ"ALL", "TECH", "FINANCE" ç­‰ï¼‰
                       "ALL" æˆ– None è¿”å›æ‰€æœ‰å®ä¾‹

    è¿”å›:
        å®ä¾‹é…ç½®å­—å…¸åˆ—è¡¨
    """
    if not INSTANCES_DIR.exists():
        return []

    instances = []
    for json_file in INSTANCES_DIR.glob("*.json"):
        try:
            with open(json_file, 'r') as f:
                instance = json.load(f)

            # åº”ç”¨è¡Œä¸šè¿‡æ»¤å™¨
            if sector_filter and sector_filter != "ALL":
                instance_sector = instance.get("sector", "").upper()
                if instance_sector != sector_filter.upper():
                    continue

            instances.append(instance)

        except json.JSONDecodeError as e:
            print(f"âš ï¸ åŠ è½½å®ä¾‹é…ç½®å¤±è´¥ {json_file}: {e}")
            continue

    return instances


def load_template(template_name: str) -> str:
    """
    ä»æ–‡ä»¶åŠ è½½ç­–ç•¥æ¨¡æ¿ã€‚

    å‚æ•°:
        template_name: æ¨¡æ¿æ–‡ä»¶åï¼ˆä¾‹å¦‚ "vol_sniper.md"ï¼‰

    è¿”å›:
        æ¨¡æ¿å†…å®¹å­—ç¬¦ä¸²

    å¼‚å¸¸:
        FileNotFoundError: å¦‚æœæ¨¡æ¿ä¸å­˜åœ¨
    """
    template_path = TEMPLATES_DIR / template_name

    if not template_path.exists():
        raise FileNotFoundError(f"æ¨¡æ¿æœªæ‰¾åˆ°: {template_name} (TEMPLATE_NOT_FOUND)")

    with open(template_path, 'r', encoding='utf-8') as f:
        return f.read()


def render_template(template_content: str, parameters: Dict[str, Any], market_data: Dict[str, Any] = None) -> str:
    """
    ä½¿ç”¨å‚æ•°å’Œå¸‚åœºæ•°æ®æ¸²æŸ“ Jinja2 æ¨¡æ¿ã€‚

    å‚æ•°:
        template_content: åŒ…å« Jinja2 å ä½ç¬¦çš„æ¨¡æ¿å­—ç¬¦ä¸²
        parameters: è¦æ³¨å…¥çš„å‚æ•°å­—å…¸
        market_data: è¦æ³¨å…¥çš„å¸‚åœºæ•°æ®å¿«ç…§ï¼ˆå¯é€‰ï¼‰

    è¿”å›:
        æ¸²æŸ“åçš„æ¨¡æ¿å­—ç¬¦ä¸²
    """
    # ä½¿ç”¨ StrictUndefined ä»¥å°½æ—©æ•è·ç¼ºå¤±çš„æ¨¡æ¿å˜é‡
    env = Environment(undefined=StrictUndefined)
    template = env.from_string(template_content)

    # åˆå¹¶ parameters å’Œ market_data ä½œä¸ºæ¨¡æ¿ä¸Šä¸‹æ–‡
    # ä¿®å¤ï¼šç¡®ä¿ 'parameters' é”®ä¹ŸåŒ…å«åœ¨ä¸Šä¸‹æ–‡ä¸­
    context = {'parameters': parameters, **parameters}
    if market_data:
        context['market_data'] = market_data

    return template.render(**context)


async def execute_single_instance(
    instance: Dict,
    market_data: Dict[str, Any],
    timeout: int = 20
) -> Optional[Signal]:
    """
    æ‰§è¡Œå•ä¸ªèœ‚ç¾¤å®ä¾‹ï¼ˆå¼‚æ­¥ï¼‰ã€‚

    æ­¤å‡½æ•°ï¼š
    1. åŠ è½½å¹¶æ¸²æŸ“æ¨¡æ¿
    2. ä¿å­˜è¾“å…¥å¿«ç…§
    3. è°ƒç”¨ LLM API
    4. è§£æå“åº”ä¸º Signal
    5. æ›´æ–°å¿«ç…§çš„å“åº”

    å‚æ•°:
        instance: å®ä¾‹é…ç½®
        market_data: å¸‚åœºæ•°æ®å¿«ç…§
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    è¿”å›:
        Signal å¯¹è±¡ï¼Œæ‰§è¡Œå¤±è´¥è¿”å› None
    """
    instance_id = instance["id"]
    template_name = instance["template"]
    parameters = instance.get("parameters", {})

    try:
        # åŠ è½½å¹¶æ¸²æŸ“æ¨¡æ¿
        template_content = load_template(template_name)
        print(f"ğŸ“‹ [{instance_id}] ç­–ç•¥æ¨¡æ¿åŠ è½½å®Œæˆ: {template_name}")

        rendered_prompt = render_template(template_content, parameters, market_data)
        print(f"âœ¨ [{instance_id}] æ¨¡æ¿æ¸²æŸ“å®Œæˆ")

        # åœ¨ LLM è°ƒç”¨ä¹‹å‰ä¿å­˜è¾“å…¥å¿«ç…§
        timestamp = datetime.now().isoformat()
        print(f"ğŸ’¾ [{instance_id}] æ­£åœ¨ä¿å­˜å†³ç­–å¿«ç…§...")
        snapshot_id = save_snapshot(
            instance_id=instance_id,
            template_name=template_name,
            rendered_prompt=rendered_prompt,
            market_data=market_data,
            agent_response=None,  # LLM è°ƒç”¨åæ›´æ–°
            timestamp=timestamp
        )
        print(f"âœ… [{instance_id}] å†³ç­–å¿«ç…§å·²ä¿å­˜: {snapshot_id}")

        # æ‰§è¡Œ LLM API è°ƒç”¨ï¼ˆå¸¦è¶…æ—¶ï¼‰
        try:
            response = await asyncio.wait_for(
                call_llm_api(rendered_prompt, market_data),
                timeout=timeout
            )
        except asyncio.TimeoutError:
            print(f"è­¦å‘Šï¼šå®ä¾‹ {instance_id} åœ¨ {timeout}ç§’åè¶…æ—¶ (TIMEOUT)")
            return None

        # è§£æå“åº”ä¸º Signal
        signal = parse_signal_response(response, instance_id, template_name)

        # æ›´æ–°å¿«ç…§çš„å“åº”
        update_snapshot_response(snapshot_id, {
            "raw_response": response,
            "parsed_signal": signal.__dict__ if signal else None
        })

        return signal

    except FileNotFoundError as e:
        print(f"è­¦å‘Šï¼š{e}")
        return None
    except Exception as e:
        print(f"âŒ æ‰§è¡Œç­–ç•¥å®ä¾‹å¤±è´¥ {instance_id}: {e}")
        return None


async def call_llm_api(prompt: str, market_data: Dict, max_retries: int = 2) -> Dict:
    """
    é€šè¿‡ OpenRouter è°ƒç”¨ LLM API ä»¥è·å–äº¤æ˜“ä¿¡å·ã€‚

    ä½¿ç”¨ Gemini 2.5 Flash è¿›è¡Œå¿«é€Ÿã€ç»æµé«˜æ•ˆçš„å¹¶å‘æ‰§è¡Œã€‚
    åŒ…å«é‡è¯•æœºåˆ¶å’Œé”™è¯¯æ¢å¤åŠŸèƒ½ã€‚

    å‚æ•°:
        prompt: æ¸²æŸ“åçš„æç¤ºè¯
        market_data: å¸‚åœºæ•°æ®ä¸Šä¸‹æ–‡
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

    è¿”å›:
        LLM å“åº”å­—å…¸ï¼ˆä» JSON å“åº”è§£æï¼‰
    """
    import os
    from openai import AsyncOpenAI

    # ä»ç¯å¢ƒå˜é‡è·å– API å¯†é’¥
    api_key = os.getenv("OPENROUTER_API_KEY")

    if not api_key:
        print("è­¦å‘Šï¼šæœªè®¾ç½® OPENROUTER_API_KEYï¼Œä½¿ç”¨æ¨¡æ‹Ÿå“åº” (NO_API_KEY)")
        # å›é€€åˆ°æ¨¡æ‹Ÿç”¨äºæµ‹è¯•
        await asyncio.sleep(0.5)
        return {
            "signal": "SHORT_PUT_SPREAD",
            "target": market_data.get("symbols", ["AAPL"])[0] if market_data.get("symbols") else "AAPL",
            "params": {
                "strike_short": 180,
                "strike_long": 175,
                "expiry": "20251128"
            },
            "confidence": 0.75,
            "reasoning": "IV å‡é«˜ä¸”æƒ…ç»ªä¸­æ€§ï¼Œè¡¨æ˜å­˜åœ¨å–å‡ºæƒåˆ©é‡‘çš„æœºä¼šã€‚"
        }

    for attempt in range(max_retries + 1):
        try:
            # åˆå§‹åŒ– OpenRouter å®¢æˆ·ç«¯ï¼ˆOpenAI å…¼å®¹ï¼‰
            client = AsyncOpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=api_key
            )

            # è°ƒæ•´æ¸©åº¦å‚æ•°ï¼Œé‡è¯•æ—¶é™ä½éšæœºæ€§
            temp = 0.7 if attempt == 0 else 0.3

            # é€šè¿‡ OpenRouter è°ƒç”¨ Gemini 2.0 Flash
            completion = await client.chat.completions.create(
                model="google/gemini-2.5-flash",  # å…è´¹å±‚ï¼Œé€Ÿåº¦éå¸¸å¿«
                messages=[
                    {
                        "role": "user",
                        "content": prompt + (f"\n\nï¼ˆç¬¬{attempt + 1}æ¬¡å°è¯•ï¼Œè¯·ç¡®ä¿è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼ï¼‰" if attempt > 0 else "")
                    }
                ],
                temperature=temp,
                max_tokens=1000,
                extra_headers={
                    "HTTP-Referer": "https://github.com/agentic-alphahive",  # å¯é€‰
                    "X-Title": "Agentic AlphaHive Runtime"  # å¯é€‰
                }
            )

            # æå–å“åº”å†…å®¹
            response_text = completion.choices[0].message.content

            # å»é™¤ markdown ä»£ç å—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            # Gemini ç»å¸¸å°† JSON åŒ…è£…åœ¨ ```json ... ``` ä¸­
            response_text = response_text.strip()
            if response_text.startswith("```"):
                # ç§»é™¤å¼€å¤´çš„ ```json æˆ– ```
                lines = response_text.split("\n")
                if lines[0].startswith("```"):
                    lines = lines[1:]
                # ç§»é™¤ç»“å°¾çš„ ```
                if lines and lines[-1].strip() == "```":
                    lines = lines[:-1]
                response_text = "\n".join(lines).strip()

            # è§£æ JSON å“åº”
            import json
            response_json = json.loads(response_text)

            # æˆåŠŸè§£æï¼Œè¿”å›ç»“æœ
            if attempt > 0:
                print(f"ğŸ”„ é‡è¯•æˆåŠŸ: ç¬¬{attempt + 1}æ¬¡å°è¯•è·å¾—æœ‰æ•ˆJSONå“åº”")

            return response_json

        except json.JSONDecodeError as e:
            print(f"âš ï¸ ç¬¬{attempt + 1}æ¬¡å°è¯•è§£æå¤±è´¥: {e}")
            print(f"ğŸ“„ å“åº”å†…å®¹: {response_text[:200]}...")

            if attempt == max_retries:
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œä½¿ç”¨æ™ºèƒ½è§£æ
                print(f"ğŸ§  ä½¿ç”¨æ™ºèƒ½è§£æå¤„ç†æœ€ç»ˆå“åº”")
                return _parse_non_json_response(response_text)
            else:
                # ç­‰å¾…åé‡è¯•
                await asyncio.sleep(1 * (attempt + 1))  # é€’å¢ç­‰å¾…æ—¶é—´

        except Exception as e:
            print(f"ğŸ”¥ ç¬¬{attempt + 1}æ¬¡APIè°ƒç”¨å¤±è´¥: {e}")
            if attempt == max_retries:
                print(f"ğŸ’¥ æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼")
                return _get_default_response(market_data)
            else:
                await asyncio.sleep(1 * (attempt + 1))  # é€’å¢ç­‰å¾…æ—¶é—´

    # è¿™ä¸ªå‡½æ•°ç°åœ¨åœ¨é‡è¯•å¾ªç¯ä¸­å¤„ç†ï¼Œä¸éœ€è¦å•ç‹¬çš„exceptå—


def _get_default_response(market_data: Dict) -> Dict:
    """
    å½“æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥æ—¶ï¼Œè¿”å›å®‰å…¨çš„é»˜è®¤å“åº”ã€‚
    """
    # ä»å¸‚åœºæ•°æ®ä¸­è·å–ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ ‡çš„
    symbols = market_data.get("symbols", [])
    target = symbols[0] if symbols else "SPY"

    return {
        "signal": "NO_TRADE",
        "target": target,
        "confidence": 0.0,
        "reasoning": "ç³»ç»Ÿé‡è¯•å¤±è´¥ï¼Œè¿”å›å®‰å…¨çš„æ— äº¤æ˜“ä¿¡å·",
        "params": {}
    }


def _parse_non_json_response(response_text: str) -> Optional[Dict]:
    """
    æ™ºèƒ½è§£æéJSONæ ¼å¼çš„AIå“åº”ï¼Œå°è¯•æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚

    å½“AIè¿”å›è‡ªç„¶è¯­è¨€æ–‡æœ¬è€Œä¸æ˜¯JSONæ—¶ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–äº¤æ˜“ä¿¡å·ã€‚
    """
    import re

    try:
        # é»˜è®¤è¿”å›å€¼
        default_response = {
            "signal": "NO_TRADE",
            "target": "",
            "confidence": 0.0,
            "reasoning": "AIå“åº”æ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨é»˜è®¤å€¼",
            "params": {}
        }

        # è½¬æ¢ä¸ºå°å†™ä»¥ä¾¿åŒ¹é…
        text_lower = response_text.lower()

        # æŸ¥æ‰¾æåˆ°çš„è‚¡ç¥¨ä»£ç 
        stock_patterns = [
            r'\b([A-Z]{2,5})\b',  # å¤§å†™è‚¡ç¥¨ä»£ç 
            r'\$([a-z]{2,5})\b'   # $ç¬¦å·åè·Ÿè‚¡ç¥¨ä»£ç 
        ]

        mentioned_stocks = []
        for pattern in stock_patterns:
            matches = re.findall(pattern, response_text, re.IGNORECASE)
            mentioned_stocks.extend(matches)

        # å»é‡å¹¶è¿‡æ»¤å¸¸è§çš„é‡‘èè¯æ±‡
        common_words = {'ETF', 'SPY', 'QQQ', 'IWM', 'THE', 'AMD', 'AAPL', 'NVDA', 'MSFT', 'GOOGL', 'META', 'TSLA', 'AMZN'}
        filtered_stocks = []
        for s in mentioned_stocks:
            if isinstance(s, str):  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
                s_upper = s.upper()
                if s_upper not in common_words or len(s_upper) <= 5:
                    filtered_stocks.append(s_upper)
        mentioned_stocks = list(set(filtered_stocks))[:3]  # æœ€å¤šå–3ä¸ª

        # æ£€æµ‹äº¤æ˜“ä¿¡å·ç±»å‹
        signal_type = "NO_TRADE"
        if any(word in text_lower for word in ['short put', 'put spread', 'å–å‡ºçœ‹è·Œ', 'çœ‹è·ŒæœŸæƒ']):
            signal_type = "SHORT_PUT_SPREAD"
        elif any(word in text_lower for word in ['short call', 'call spread', 'å–å‡ºçœ‹æ¶¨', 'çœ‹æ¶¨æœŸæƒ']):
            signal_type = "SHORT_CALL_SPREAD"
        elif any(word in text_lower for word in ['iron condor', 'é“é¹°', 'ä¸­æ€§ç­–ç•¥']):
            signal_type = "IRON_CONDOR"
        elif any(word in text_lower for word in ['credit spread', 'ä»·å·®']):
            signal_type = "CREDIT_SPREAD"
        elif any(word in text_lower for word in ['buy call', 'ä¹°å…¥çœ‹æ¶¨', 'çœ‹æ¶¨']):
            signal_type = "LONG_CALL"
        elif any(word in text_lower for word in ['buy put', 'ä¹°å…¥çœ‹è·Œ', 'çœ‹è·Œ']):
            signal_type = "LONG_PUT"

        # æ£€æµ‹ç½®ä¿¡åº¦
        confidence = 0.0
        confidence_patterns = [
            r'ç½®ä¿¡åº¦[:ï¼š]\s*(\d+(?:\.\d+)?)',
            r'confidence[:ï¼š]\s*(\d+(?:\.\d+)?)',
            r'(\d+(?:\.\d+)?)\s*%?\s*ç½®ä¿¡åº¦',
            r'(\d+(?:\.\d+)?)\s*%?\s*confidence'
        ]

        for pattern in confidence_patterns:
            match = re.search(pattern, response_text, re.IGNORECASE)
            if match:
                try:
                    conf_value = float(match.group(1))
                    confidence = min(conf_value / 100 if conf_value > 1 else conf_value, 1.0)
                    break
                except:
                    continue

        # æ£€æµ‹ç›®æ ‡æ ‡çš„
        target = mentioned_stocks[0] if mentioned_stocks else "SPY"  # é»˜è®¤SPY

        # æå–æ¨ç†ï¼ˆå–å‰100ä¸ªå­—ç¬¦ï¼‰
        reasoning = response_text.strip()[:150] + "..." if len(response_text) > 150 else response_text.strip()

        # å¦‚æœæ£€æµ‹åˆ°æœ‰æ•ˆä¿¡å·ï¼Œä½¿ç”¨æå–çš„ä¿¡æ¯
        if signal_type != "NO_TRADE" and confidence > 0.1:
            print(f"ğŸ§  æ™ºèƒ½è§£ææˆåŠŸ: æ£€æµ‹åˆ° {signal_type} ä¿¡å·ï¼Œç½®ä¿¡åº¦ {confidence:.2f}")
            return {
                "signal": signal_type,
                "target": target,
                "confidence": confidence,
                "reasoning": reasoning,
                "params": {}  # ä»è‡ªç„¶è¯­è¨€ä¸­æå–å‚æ•°æ¯”è¾ƒå¤æ‚ï¼Œæš‚æ—¶ä¸ºç©º
            }
        else:
            print(f"ğŸ¤” æœªæ£€æµ‹åˆ°æ˜ç¡®äº¤æ˜“ä¿¡å·ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return default_response

    except Exception as e:
        print(f"ğŸ”§ æ™ºèƒ½è§£æå¤±è´¥: {e}")
        return {
            "signal": "NO_TRADE",
            "target": "",
            "confidence": 0.0,
            "reasoning": f"æ™ºèƒ½è§£æå‡ºé”™: {str(e)}",
            "params": {}
        }


def parse_signal_response(response: Dict, instance_id: str, template_name: str) -> Optional[Signal]:
    """
    å°† LLM å“åº”è§£æä¸º Signal å¯¹è±¡ã€‚

    å‚æ•°:
        response: LLM API å“åº”
        instance_id: å®ä¾‹æ ‡è¯†ç¬¦
        template_name: ä½¿ç”¨çš„æ¨¡æ¿

    è¿”å›:
        Signal å¯¹è±¡ï¼Œè§£æå¤±è´¥è¿”å› None
    """
    # ä¿®å¤ï¼šæ£€æŸ¥ response æ˜¯å¦ä¸º None
    if response is None:
        print(f"âš ï¸ AI å“åº”ä¸ºç©º {instance_id}: æ— æ³•è§£æç©ºå“åº”")
        return None

    try:
        return Signal(
            instance_id=instance_id,
            template_used=template_name,
            target=response.get("target", ""),
            signal=response.get("signal", "NO_TRADE"),
            params=response.get("params", {}),
            confidence=float(response.get("confidence", 0.0)),
            reasoning=response.get("reasoning", "")
        )
    except (KeyError, ValueError) as e:
        print(f"âš ï¸ è§£æäº¤æ˜“ä¿¡å·å¤±è´¥ {instance_id}: {e}")
        return None


def deduplicate_signals(signals: List[Signal]) -> List[Signal]:
    """
    ç§»é™¤é’ˆå¯¹ç›¸åŒæ ‡çš„ä½¿ç”¨ç›¸åŒç­–ç•¥çš„é‡å¤ä¿¡å·ã€‚

    å½“å¤šä¸ªå®ä¾‹äº§ç”Ÿç›¸åŒä¿¡å·æ—¶ï¼Œä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„é‚£ä¸ªã€‚

    å‚æ•°:
        signals: Signal å¯¹è±¡åˆ—è¡¨

    è¿”å›:
        å»é‡åçš„ä¿¡å·åˆ—è¡¨
    """
    # æŒ‰ (target, signal) åˆ†ç»„
    signal_groups = {}
    for signal in signals:
        key = (signal.target, signal.signal)
        if key not in signal_groups:
            signal_groups[key] = []
        signal_groups[key].append(signal)

    # ä»æ¯ç»„ä¸­ä¿ç•™æœ€é«˜ç½®ä¿¡åº¦çš„ä¿¡å·
    deduplicated = []
    for key, group in signal_groups.items():
        best_signal = max(group, key=lambda s: s.confidence)
        deduplicated.append(best_signal)

    return deduplicated


async def execute_swarm_concurrent(
    instances: List[Dict],
    market_data: Dict[str, Any],
    max_concurrent: int = 50
) -> List[Signal]:
    """
    å¹¶å‘æ‰§è¡Œå¤šä¸ªèœ‚ç¾¤å®ä¾‹ã€‚

    å‚æ•°:
        instances: å®ä¾‹é…ç½®åˆ—è¡¨
        market_data: å¸‚åœºæ•°æ®å¿«ç…§
        max_concurrent: æœ€å¤§å¹¶å‘ LLM API è°ƒç”¨æ•°

    è¿”å›:
        æˆåŠŸæ‰§è¡Œçš„ Signal å¯¹è±¡åˆ—è¡¨
    """
    # åˆ›å»ºä¿¡å·é‡ä»¥é™åˆ¶å¹¶å‘
    semaphore = asyncio.Semaphore(max_concurrent)

    async def execute_with_semaphore(instance):
        async with semaphore:
            return await execute_single_instance(instance, market_data)

    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å®ä¾‹
    tasks = [execute_with_semaphore(inst) for inst in instances]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # è¿‡æ»¤æ‰ None å’Œå¼‚å¸¸ç»“æœ
    signals = []
    for result in results:
        if isinstance(result, Signal):
            signals.append(result)
        elif isinstance(result, Exception):
            print(f"è­¦å‘Šï¼šå®ä¾‹æ‰§è¡Œå¤±è´¥å¹¶æŠ›å‡ºå¼‚å¸¸: {result} (INSTANCE_EXCEPTION)")

    return signals


def consult_swarm(
    sector: str = "ALL",
    market_data: Optional[Dict] = None,
    max_concurrent: int = 50,
    skip_data_validation: bool = False
) -> List[Dict]:
    """
    æ‰§è¡Œèœ‚ç¾¤æ™ºèƒ½åˆ†æã€‚

    è¿™æ˜¯ Commander è°ƒç”¨èœ‚ç¾¤çš„ä¸»è¦å…¥å£ç‚¹ã€‚

    å‚æ•°:
        sector: æŒ‰è¡Œä¸šè¿‡æ»¤å®ä¾‹ï¼ˆ"ALL", "TECH", "FINANCE" ç­‰ï¼‰
        market_data: å½“å‰å¸‚åœºå¿«ç…§ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™è·å–æœ€æ–°æ•°æ®ï¼‰
        max_concurrent: æœ€å¤§å¹¶å‘ LLM API è°ƒç”¨æ•°
        skip_data_validation: è·³è¿‡æ•°æ®è´¨é‡éªŒè¯ï¼ˆä¸æ¨èï¼‰

    è¿”å›:
        ä¿¡å·å­—å…¸åˆ—è¡¨ï¼Œç»“æ„å¦‚ä¸‹:
        [
            {
                "instance_id": "tech_aggressive",
                "template_used": "vol_sniper",
                "target": "NVDA",
                "signal": "SHORT_PUT_SPREAD",
                "params": {"strike_short": 120, "strike_long": 115},
                "confidence": 0.88,
                "reasoning": "..."
            },
            ...
        ]

    ç¤ºä¾‹:
        >>> signals = consult_swarm(sector="TECH")
        >>> print(f"æ”¶åˆ° {len(signals)} ä¸ªä¿¡å·")
        æ”¶åˆ° 3 ä¸ªä¿¡å·
    """
    # åŠ è½½æ´»è·ƒå®ä¾‹
    instances = load_instances(sector_filter=sector)

    if not instances:
        print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°è¡Œä¸š '{sector}' çš„æ´»è·ƒå®ä¾‹ (NO_INSTANCES)")
        return []

    # å¦‚æœæœªæä¾›å¸‚åœºæ•°æ®åˆ™è·å–
    if market_data is None:
        market_data = fetch_market_snapshot()

    # === æ•°æ®è´¨é‡é£è¡Œå‰æ£€æŸ¥ ===
    if not skip_data_validation:
        from skills.data_quality import validate_data_quality, auto_trigger_backfill

        # ä» market_data å¿«ç…§ä¸­æå–æ ‡çš„
        symbols = []
        if market_data and 'snapshot' in market_data:
            symbols = list(market_data['snapshot'].keys())

        # åŒæ—¶æ”¶é›†å®ä¾‹æ ‡çš„æ± ä¸­çš„æ ‡çš„
        for instance in instances:
            symbol_pool = instance.get('parameters', {}).get('symbol_pool', [])
            symbols.extend(symbol_pool)

        # å»é‡
        symbols = list(set(symbols))

        if symbols:
            print(f"\nğŸ” æ•°æ®è´¨é‡å‰ç½®æ£€æŸ¥")
            print(f"ğŸ“Š æ­£åœ¨éªŒè¯ {len(symbols)} ä¸ªæ ‡çš„çš„æ•°æ®...")

            # éªŒè¯æ•°æ®è´¨é‡
            validation = validate_data_quality(
                symbols=symbols,
                min_daily_bars=20,  # ä»30é™ä½ä»¥æ›´å®½æ¾çš„æ£€æŸ¥
                min_hourly_bars=30,
                min_5min_bars=200,
                max_age_hours=8,  # å…è®¸ç¨å¾®è¿‡æ—¶çš„æ•°æ®
                require_all_intervals=False  # å®½æ¾è¦æ±‚
            )

            if not validation['valid']:
                print(f"\nâš ï¸  æ•°æ®è´¨é‡éªŒè¯å¤±è´¥ (DATA_QUALITY_FAILED)")
                print(f"æ‘˜è¦: {validation['summary']}")
                print(f"\nå‘ç°çš„é—®é¢˜:")

                # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„é—®é¢˜
                critical_issues = [i for i in validation['issues'] if i['severity'] == 'CRITICAL']
                high_issues = [i for i in validation['issues'] if i['severity'] == 'HIGH']

                if critical_issues:
                    print(f"  ä¸¥é‡ ({len(critical_issues)}):")
                    for issue in critical_issues[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                        print(f"    - {issue['symbol']}: {issue['issue']} ({issue['detail']})")

                if high_issues:
                    print(f"  é«˜ ({len(high_issues)}):")
                    for issue in high_issues[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                        print(f"    - {issue['symbol']}: {issue['issue']} ({issue['detail']})")

                print(f"\nå»ºè®®:")
                for rec in validation['recommendations']:
                    print(f"  â†’ {rec}")

                # è¿”å›å¸¦æœ‰æ•°æ®è´¨é‡è¯´æ˜çš„ NO_TRADE ä¿¡å·
                print(f"\nâœ— ç»ˆæ­¢èœ‚ç¾¤å’¨è¯¢ - æ•°æ®è´¨é‡ä¸è¶³")
                print(f"  ç”±äºæ•°æ®è´¨é‡é—®é¢˜è¿”å› NO_TRADE ä¿¡å·\n")

                return [{
                    "instance_id": "DATA_QUALITY_CHECK",
                    "template_used": "N/A",
                    "target": "N/A",
                    "signal": "NO_TRADE",
                    "params": {},
                    "confidence": 0.0,
                    "reasoning": (
                        f"æ•°æ®è´¨é‡éªŒè¯å¤±è´¥: {validation['summary']}ã€‚"
                        f"å‘ç° {len(critical_issues)} ä¸ªä¸¥é‡å’Œ {len(high_issues)} ä¸ªé«˜ä¸¥é‡åº¦é—®é¢˜ã€‚"
                        f"å»ºè®®: {'; '.join(validation['recommendations'])}"
                    )
                }]
            else:
                print(f"âœ… æ•°æ®è´¨é‡éªŒè¯é€šè¿‡")
                print(f"ğŸ“Š {len(validation['symbols_passed'])}/{len(symbols)} ä¸ªæ ‡çš„æ•°æ®å……è¶³\n")
        else:
            print(f"âš ï¸  æœªæä¾›æ ‡çš„ç”¨äºæ•°æ®è´¨é‡éªŒè¯ (NO_SYMBOLS)")
            print(f"  è°¨æ…ç»§ç»­ - èœ‚ç¾¤å¯èƒ½å› ç¼ºå°‘æ•°æ®è€Œå¤±è´¥\n")

    # å¹¶å‘æ‰§è¡Œèœ‚ç¾¤
    loop = asyncio.get_event_loop()
    signals = loop.run_until_complete(
        execute_swarm_concurrent(instances, market_data, max_concurrent)
    )

    # å»é‡ä¿¡å·
    signals = deduplicate_signals(signals)

    # å°† Signal å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
    signal_dicts = [
        {
            "instance_id": s.instance_id,
            "template_used": s.template_used,
            "target": s.target,
            "signal": s.signal,
            "params": s.params,
            "confidence": s.confidence,
            "reasoning": s.reasoning
        }
        for s in signals
    ]

    # ç”¨å¯æ‰§è¡Œçš„è…¿ä¸°å¯Œä¿¡å·ï¼ˆå¦‚æœå°šæœªå­˜åœ¨ï¼‰
    enriched_signals = []
    for sig in signal_dicts:
        enriched = enrich_signal(sig, market_data)

        # éªŒè¯ä¸°å¯ŒåŒ–
        if validate_enriched_signal(enriched):
            enriched_signals.append(enriched)
        else:
            print(f"è­¦å‘Šï¼šæ¥è‡ª {sig['instance_id']} çš„ä¿¡å·åœ¨ä¸°å¯ŒåŒ–åéªŒè¯å¤±è´¥ (ENRICHMENT_VALIDATION_FAILED)")
            # ä»ç„¶åŒ…å«å®ƒï¼Œä½†æ ‡è®°ä¸ºä¸å®Œæ•´
            enriched_signals.append(enriched)

    return enriched_signals


def fetch_market_snapshot() -> Dict[str, Any]:
    """
    è·å–å½“å‰å¸‚åœºæ•°æ®å¿«ç…§ã€‚

    TODO: é›†æˆ ThetaData MCP æœåŠ¡å™¨ä»¥è·å–çœŸå®å¸‚åœºæ•°æ®ã€‚

    è¿”å›:
        å¸‚åœºæ•°æ®å­—å…¸
    """
    # å¸‚åœºæ•°æ®è·å–çš„å ä½ç¬¦
    # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè°ƒç”¨ ThetaData MCP æœåŠ¡å™¨ï¼š
    # - è·å–æ ‡çš„æ± çš„æŠ¥ä»·
    # - è·å–æœŸæƒé“¾
    # - è®¡ç®— IV rank/ç™¾åˆ†ä½
    return {
        "timestamp": datetime.now().isoformat(),
        "symbols": ["AAPL", "NVDA", "AMD"],
        "quotes": {},
        "options_chains": {}
    }
